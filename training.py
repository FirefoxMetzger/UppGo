from keras.losses import mean_squared_error, categorical_crossentropy
from keras.optimizers import adam
from keras.metrics import categorical_accuracy, top_k_categorical_accuracy
from keras.callbacks import ModelCheckpoint
from pathlib import Path
import keras

from network import AlphaZero
from load_data import create_dataset, ReplayQueue

import tensorflow as tf

session = tf.Session()
keras.backend.set_session(session)


def moves_predicted(y_true, y_pred):
    val = categorical_accuracy(y_true, y_pred)
    return val


def moves_top10(y_true, y_pred):
    val = top_k_categorical_accuracy(y_true, y_pred, k=10)
    return val

batch_size = 32

# --- Dataset Creation ---
dataset_generator = create_dataset(
    Path("numpy/training"),
    Path("numpy/test"),
    Path("numpy/validation"),
)
training_dataset = tf.data.Dataset.from_generator(
    dataset_generator["training"]["feeder"].__iter__,
    (tf.float32, tf.float32, tf.float32),
    (tf.TensorShape([19, 19, 17]), tf.TensorShape([362]), tf.TensorShape([]))
).batch(batch_size)

validation_dataset = tf.data.Dataset.from_generator(
    dataset_generator["validation"]["feeder"].__iter__,
    (tf.float32, tf.float32, tf.float32),
    (tf.TensorShape([19, 19, 17]), tf.TensorShape([362]), tf.TensorShape([]))
).batch(batch_size)

test_dataset = tf.data.Dataset.from_generator(
    dataset_generator["test"]["feeder"].__iter__,
    (tf.float32, tf.float32, tf.float32),
    (tf.TensorShape([19, 19, 17]), tf.TensorShape([362]), tf.TensorShape([]))
).batch(batch_size)


# --- Iterator Creation ---
iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
example, action, value = iterator.get_next()
train_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)
test_init_op = iterator.make_initializer(test_dataset)

# --- Model Creation ---

"""
model = keras.Model(input_tensor, AlphaZero(input_tensor))
"""
input_vals = keras.layers.Input(tensor=example)

#output1 = keras.layers.Dense(362, activation='sigmoid', name="out1")(mid)
#output2 = keras.layers.Dense(1, activation='relu', name="out2")(mid)
#model = keras.Model(input_vals, [output1, output2])
model = AlphaZero(input_vals, residual_blocks=2)
model.compile(
    adam(),
    loss={
        "policy": categorical_crossentropy,
        "value": mean_squared_error
    },
    loss_weights={
        "policy": 1,
        "value": 0.01
    },
    metrics={
        "policy": [moves_predicted, moves_top10],
        "value": []
    },
    target_tensors=[
        action,
        value
    ]
)

# --- Training ---
for epochs in range(5):
    session.run(train_init_op)
    model.fit(
        epochs=1,
        steps_per_epoch=100
    )

    session.run(validation_init_op)
    result = model.evaluate(steps=100)

session.run(test_init_op)
result = model.evaluate(steps=100)

print(result)

# final 2 million games of self-play data generated by previous run of AlphaZero
#aneahling rate, momentum, regularization hyperparameter as in supervised learning experiment
# equal weight on cross entropy and MSE

# mini batch size = 2048 ; 3.1 million mini batches; 40 days training
# 2048 elements split in units of 32 across 64 GPUs
# use the most recent 500,000 games and sample uniformly
# momentum = 0.9
# checkpoint every 1000 steps; may be used to generate new data

# learning rates
# 0 - 400k      0.01
# 400k - 600k   0.001
# >600k         0.0001